{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT Coding Example with Python\n",
    "\n",
    "## Welcome\n",
    "Welcome to the ChatGPT Coding Example with Python notebook. This file is used to showcase some methods used to interact with Large Language Models (LLMs) and get productive results. Specifically, we will be using ChatGPT to interact with social media to gather information. In part two, we will look at prompt engineering techniques to elicit specific responses from the model. \n",
    "\n",
    "_Note: all code follows PEP 8 standards_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global imports\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import openai\n",
    "from pandas import json_normalize\n",
    "\n",
    "# Constants\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Configure OpenAI API key\n",
    "openai.api_key = OPENAI_API_KEY\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Media Listening \n",
    "\n",
    "In the following scenario, a client (Sam's Club) has asked us to build an app that allows us to keep track of what people say about their brand on social media. A core component of this application is based upon AI capabilities to extract information from the interactions. For this example, we will create three components to process X posts (aka Tweets), and extract information about them in three stages:\n",
    "\n",
    "1. Sentiment and Emotion Analysis: Analyze the predominant sentiment and emotion of each tweet.\n",
    "2. Topic modelling: Find the common topics discussed.\n",
    "3. Categorization: Classify the posts into predefined categories (Content Quality, Customer Support, Spam, Membership Issues, Marketing, or Other)\n",
    "\n",
    "After processing the posts, our solution will create a table with all the information needed to create a report."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "We have extracted the posts into a JSON file (posts.json). To simplify processing we will eliminate some features to more closely align with our goals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       created_at                   id               id_str  \\\n",
      "0  Mon May 15 18:21:47 +0000 2023  1658175862045302797  1658175862045302797   \n",
      "1  Mon May 15 17:29:18 +0000 2023  1658162654479888397  1658162654479888397   \n",
      "2  Mon May 15 17:04:13 +0000 2023  1658156342199332864  1658156342199332864   \n",
      "3  Mon May 15 16:54:52 +0000 2023  1658153988703809536  1658153988703809536   \n",
      "4  Mon May 15 16:54:24 +0000 2023  1658153870575521793  1658153870575521793   \n",
      "\n",
      "                                           full_text  truncated  \\\n",
      "0  KitchenAid Mixer Sale on @SamsClub | $90 Off P...      False   \n",
      "1           @KellieShai_ All we need is some milk. üç™      False   \n",
      "2  Happy National Chocolate Chip Day! No denying ...      False   \n",
      "3  This is heartbreaking that less than a year im...      False   \n",
      "4  @VIZIOsupport I bought a vizio tv from @SamsCl...      False   \n",
      "\n",
      "  display_text_range                                             source  \\\n",
      "0           [0, 128]  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
      "1           [13, 40]  <a href=\"https://prod1.sprinklr.com\" rel=\"nofo...   \n",
      "2           [0, 276]  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
      "3           [0, 168]  <a href=\"http://twitter.com/download/android\" ...   \n",
      "4           [0, 279]  <a href=\"http://twitter.com/download/android\" ...   \n",
      "\n",
      "   in_reply_to_status_id in_reply_to_status_id_str  in_reply_to_user_id  ...  \\\n",
      "0                    NaN                      None                  NaN  ...   \n",
      "1           1.658156e+18       1658156342199332864         1.629262e+18  ...   \n",
      "2                    NaN                      None                  NaN  ...   \n",
      "3           1.658154e+18       1658153870575521793         1.620974e+18  ...   \n",
      "4                    NaN                      None         6.915388e+07  ...   \n",
      "\n",
      "  place.contained_within place.bounding_box.type  \\\n",
      "0                    NaN                     NaN   \n",
      "1                    NaN                     NaN   \n",
      "2                    NaN                     NaN   \n",
      "3                    NaN                     NaN   \n",
      "4                    NaN                     NaN   \n",
      "\n",
      "   place.bounding_box.coordinates  geo.type  geo.coordinates coordinates.type  \\\n",
      "0                             NaN       NaN              NaN              NaN   \n",
      "1                             NaN       NaN              NaN              NaN   \n",
      "2                             NaN       NaN              NaN              NaN   \n",
      "3                             NaN       NaN              NaN              NaN   \n",
      "4                             NaN       NaN              NaN              NaN   \n",
      "\n",
      "   coordinates.coordinates  quoted_status.quoted_status_id  \\\n",
      "0                      NaN                             NaN   \n",
      "1                      NaN                             NaN   \n",
      "2                      NaN                             NaN   \n",
      "3                      NaN                             NaN   \n",
      "4                      NaN                             NaN   \n",
      "\n",
      "   quoted_status.quoted_status_id_str  quoted_status.possibly_sensitive  \n",
      "0                                 NaN                               NaN  \n",
      "1                                 NaN                               NaN  \n",
      "2                                 NaN                               NaN  \n",
      "3                                 NaN                               NaN  \n",
      "4                                 NaN                               NaN  \n",
      "\n",
      "[5 rows x 241 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read JSON data from \"posts.json\" and convert it to a DataFrame\n",
    "try:\n",
    "    with open(\"posts.json\") as file:\n",
    "        data = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file name and path.\")\n",
    "    # Handle the exception as needed\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error decoding JSON. Please check the file content.\")\n",
    "    # Handle the exception as needed\n",
    "else:\n",
    "    # Flatten the JSON data into a DataFrame\n",
    "    df = json_normalize(data)\n",
    "\n",
    "    # Display the first 5 rows of the DataFrame\n",
    "    print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       created_at                   id  \\\n",
      "0  Mon May 15 18:21:47 +0000 2023  1658175862045302797   \n",
      "1  Mon May 15 17:29:18 +0000 2023  1658162654479888397   \n",
      "2  Mon May 15 17:04:13 +0000 2023  1658156342199332864   \n",
      "3  Mon May 15 16:54:52 +0000 2023  1658153988703809536   \n",
      "4  Mon May 15 16:54:24 +0000 2023  1658153870575521793   \n",
      "\n",
      "                                           full_text in_reply_to_screen_name  \\\n",
      "0  KitchenAid Mixer Sale on @SamsClub | $90 Off P...                    None   \n",
      "1           @KellieShai_ All we need is some milk. üç™             KellieShai_   \n",
      "2  Happy National Chocolate Chip Day! No denying ...                    None   \n",
      "3  This is heartbreaking that less than a year im...                Roja1670   \n",
      "4  @VIZIOsupport I bought a vizio tv from @SamsCl...            VIZIOsupport   \n",
      "\n",
      "  metadata.iso_language_code metadata.result_type              user.id  \\\n",
      "0                         en               recent             20445389   \n",
      "1                         en               recent             86089860   \n",
      "2                         en               recent  1629261957860556800   \n",
      "3                         en               recent  1620973692812496896   \n",
      "4                         en               recent  1620973692812496896   \n",
      "\n",
      "           user.id_str                          user.name user.screen_name  \\\n",
      "0             20445389                           Hip2Save         Hip2Save   \n",
      "1             86089860                         Sam‚Äôs Club         SamsClub   \n",
      "2  1629261957860556800  Celebrate EveryDay by Kellie ShƒÅi      KellieShai_   \n",
      "3  1620973692812496896                    La Sombra Negra         Roja1670   \n",
      "4  1620973692812496896                    La Sombra Negra         Roja1670   \n",
      "\n",
      "   ... user.profile_text_color user.profile_use_background_image  \\\n",
      "0  ...                  333333                              True   \n",
      "1  ...                  333333                             False   \n",
      "2  ...                  333333                              True   \n",
      "3  ...                  333333                              True   \n",
      "4  ...                  333333                              True   \n",
      "\n",
      "  user.has_extended_profile user.default_profile user.default_profile_image  \\\n",
      "0                      True                False                      False   \n",
      "1                     False                False                      False   \n",
      "2                      True                 True                      False   \n",
      "3                      True                 True                      False   \n",
      "4                      True                 True                      False   \n",
      "\n",
      "   user.following  user.follow_request_sent  user.notifications  \\\n",
      "0           False                     False               False   \n",
      "1           False                     False               False   \n",
      "2           False                     False               False   \n",
      "3           False                     False               False   \n",
      "4           False                     False               False   \n",
      "\n",
      "   user.translator_type user.withheld_in_countries  \n",
      "0                  none                         []  \n",
      "1                  none                         []  \n",
      "2                  none                         []  \n",
      "3                  none                         []  \n",
      "4                  none                         []  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get a list of all column names in the DataFrame\n",
    "    all_columns = df.columns.tolist()\n",
    "\n",
    "    # Define the base column names to retain\n",
    "    base_columns_to_keep = ['created_at', 'id', 'full_text', 'in_reply_to_screen_name']\n",
    "\n",
    "    # Add columns that start with 'metadata.' or 'user.' to the list of columns to keep\n",
    "    additional_columns_to_keep = [col for col in all_columns if col.startswith('metadata.') or col.startswith('user.')]\n",
    "    columns_to_keep = base_columns_to_keep + additional_columns_to_keep\n",
    "\n",
    "    # Update the DataFrame to include only the specified columns\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # Display the first 5 rows of the DataFrame\n",
    "    print(df.head())\n",
    "\n",
    "\n",
    "except NameError:\n",
    "    print(\"DataFrame 'df' is not defined. Please ensure it is created and loaded correctly.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Key error: {e}. Please ensure the specified columns exist in the DataFrame.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       created_at                   id  \\\n",
      "0  Mon May 15 18:21:47 +0000 2023  1658175862045302797   \n",
      "1  Mon May 15 17:29:18 +0000 2023  1658162654479888397   \n",
      "2  Mon May 15 17:04:13 +0000 2023  1658156342199332864   \n",
      "3  Mon May 15 16:54:52 +0000 2023  1658153988703809536   \n",
      "4  Mon May 15 16:54:24 +0000 2023  1658153870575521793   \n",
      "\n",
      "                                           full_text in_reply_to_screen_name  \\\n",
      "0  KitchenAid Mixer Sale on @SamsClub | $90 Off P...                    None   \n",
      "1           @KellieShai_ All we need is some milk. üç™             KellieShai_   \n",
      "2  Happy National Chocolate Chip Day! No denying ...                    None   \n",
      "3  This is heartbreaking that less than a year im...                Roja1670   \n",
      "4  @VIZIOsupport I bought a vizio tv from @SamsCl...            VIZIOsupport   \n",
      "\n",
      "  metadata.iso_language_code metadata.result_type              user.id  \\\n",
      "0                         en               recent             20445389   \n",
      "1                         en               recent             86089860   \n",
      "2                         en               recent  1629261957860556800   \n",
      "3                         en               recent  1620973692812496896   \n",
      "4                         en               recent  1620973692812496896   \n",
      "\n",
      "           user.id_str                          user.name user.screen_name  \\\n",
      "0             20445389                           Hip2Save         Hip2Save   \n",
      "1             86089860                         Sam‚Äôs Club         SamsClub   \n",
      "2  1629261957860556800  Celebrate EveryDay by Kellie ShƒÅi      KellieShai_   \n",
      "3  1620973692812496896                    La Sombra Negra         Roja1670   \n",
      "4  1620973692812496896                    La Sombra Negra         Roja1670   \n",
      "\n",
      "   ... user.profile_sidebar_fill_color user.profile_text_color  \\\n",
      "0  ...                          F6F6F6                  333333   \n",
      "1  ...                          DDEEF6                  333333   \n",
      "2  ...                          DDEEF6                  333333   \n",
      "3  ...                          DDEEF6                  333333   \n",
      "4  ...                          DDEEF6                  333333   \n",
      "\n",
      "  user.profile_use_background_image user.has_extended_profile  \\\n",
      "0                              True                      True   \n",
      "1                             False                     False   \n",
      "2                              True                      True   \n",
      "3                              True                      True   \n",
      "4                              True                      True   \n",
      "\n",
      "  user.default_profile  user.default_profile_image  user.following  \\\n",
      "0                False                       False           False   \n",
      "1                False                       False           False   \n",
      "2                 True                       False           False   \n",
      "3                 True                       False           False   \n",
      "4                 True                       False           False   \n",
      "\n",
      "   user.follow_request_sent  user.notifications user.translator_type  \n",
      "0                     False               False                 none  \n",
      "1                     False               False                 none  \n",
      "2                     False               False                 none  \n",
      "3                     False               False                 none  \n",
      "4                     False               False                 none  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Drop columns where all elements are missing and the 'user.withheld_in_countries' column\n",
    "    df = df.dropna(axis=1, how='all').drop(columns=['user.withheld_in_countries'])\n",
    "\n",
    "    # Display the first 5 rows of the DataFrame\n",
    "    print(df.head())\n",
    "\n",
    "\n",
    "except NameError:\n",
    "    print(\"DataFrame 'df' is not defined. Please ensure it is created and loaded correctly.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Key error: {e}. Please ensure the specified columns exist in the DataFrame.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment and Emotion Analysis\n",
    "\n",
    "Define our function for sentiment and emotion analysis. \n",
    "\n",
    "For each post, we want to find out the predominant sentiment: Positive(1), Neutral(0), Negative(-1).\n",
    "\n",
    "Also, we will provide a more nuanced value to represent the emotion: Joy(1), Surprise(0.80), Neutral(0.60), Sadness(0.40), Mistrust(0.20), and Disgust(0).\n",
    "\n",
    "_Note: Keep in mind that, prompts can handle a fixed amount of tokens so we should check that we're not exceeding the amount of tokens when creating our function._\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sentiment_emotion_analysis(df):\n",
    "    \"\"\"\n",
    "    Perform sentiment and emotion analysis on each post in a DataFrame.\n",
    "\n",
    "    This function iterates through each post contained in the 'full_text' column of the input DataFrame.\n",
    "    For each post, it constructs a prompt and sends it to the OpenAI API to perform sentiment analysis\n",
    "    and emotion detection. The sentiment is categorized as Positive (1), Neutral (0), or Negative (-1).\n",
    "    Additionally, the emotion is represented by a nuanced value: Joy (1), Surprise (0.80), Neutral (0.60),\n",
    "    Sadness (0.40), Mistrust (0.20), and Disgust (0). The function handles JSON decoding errors and\n",
    "    general exceptions during the API response parsing and logs these errors.\n",
    "\n",
    "    The results of the sentiment and emotion analysis are appended to the DataFrame as new columns,\n",
    "    namely 'sentiment', 'sentiment_value', 'emotion', and 'emotion_value', where each entry corresponds\n",
    "    to the analysis results of the respective post.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): A pandas DataFrame containing a column 'full_text' with posts to analyze.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The modified DataFrame with added columns for sentiment ('sentiment', 'sentiment_value')\n",
    "    and emotion ('emotion', 'emotion_value') analysis results.\n",
    "\n",
    "    Exceptions:\n",
    "    - JSONDecodeError: Handles exceptions related to JSON decoding errors in the API response.\n",
    "    - Exception: Catches and logs any other general exceptions that may occur during the API call or response parsing.\n",
    "\n",
    "    Note:\n",
    "    The function requires an active OpenAI API key set up in the environment to perform the analysis.\n",
    "    \"\"\"\n",
    "    sentiments = []\n",
    "    emotions = []\n",
    "\n",
    "    for post in df['full_text']:\n",
    "\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=\"gpt-4-turbo-preview\",\n",
    "                response_format={ \"type\": \"json_object\" },\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that looks at posts (aka tweets), then determines sentiment and emotion. Analyze the sentiment of the following posts and categorize them as Positive (1), Neutral (0), or Negative (-1). Also, assign an emotion to the post, with a corresponding value: Joy (1), Surprise (0.80), Neutral (0.60),Sadness (0.40), Mistrust (0.20), and Disgust (0). Return the analysis in a JSON format, consisting solely of the 'sentiment' and 'emotion' keys with their respective values('sentiment_value' and 'emotion_value'). Exclude all other information or text that is not part of the JSON format.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\" Post: {post}\"},\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=100,\n",
    "                top_p=0.50,\n",
    "                frequency_penalty=0.0,\n",
    "                presence_penalty=0.0\n",
    "            )\n",
    "            \n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "        \n",
    "\n",
    "            # Check if response text is in JSON format\n",
    "            if response_text.startswith('{') and response_text.endswith('}'):\n",
    "                response_json = json.loads(response_text)\n",
    "                sentiments.append(response_json[\"sentiment\"])\n",
    "                emotions.append(response_json[\"emotion\"])\n",
    "            else:\n",
    "                logging.error(f\"Invalid JSON format for post: {post}\")\n",
    "                sentiments.append((\"Invalid Format\", 0))\n",
    "                emotions.append((\"Invalid Format\", 0))\n",
    "\n",
    "        except json.JSONDecodeError as json_error:\n",
    "            logging.error(f\"JSON decoding error for post: {post}, Error: {json_error}\")\n",
    "            sentiments.append((\"Error\", 0))\n",
    "            emotions.append((\"Error\", 0))\n",
    "        \n",
    "\n",
    "    df['sentiment'] = sentiments\n",
    "    df['emotion'] = emotions\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "\n",
    "Define our function for topic extraction. For each post find out the broader topic discussed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the get_topic function to determine the topic of a post\n",
    "def get_topic(post):\n",
    "    \"\"\"\n",
    "    Determines the topic of a post (tweet) using the OpenAI API.\n",
    "    The topic is derived in one or two words and returned in sentence case.\n",
    "    \"\"\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that looks at posts (aka tweets), then determines the topic or subject in one or two words. The topic should be broad enough to cover a large number of posts, but specific enough to be useful. Put all topics in sentence case and don't include any punctuation at the end of the topic. Respond with: The topic of this post is:<topic>\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Post: {post}\"}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=60,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    \n",
    "    response_text = response.choices[0].message.content.strip().replace(\"The topic of this post is: \", \"\")\n",
    "    return response_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Results\n",
    "\n",
    "Generate our sentiment, emotion, and topic and merge it into our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       created_at                   id  \\\n",
      "0  Mon May 15 18:21:47 +0000 2023  1658175862045302797   \n",
      "1  Mon May 15 17:29:18 +0000 2023  1658162654479888397   \n",
      "2  Mon May 15 17:04:13 +0000 2023  1658156342199332864   \n",
      "3  Mon May 15 16:54:52 +0000 2023  1658153988703809536   \n",
      "4  Mon May 15 16:54:24 +0000 2023  1658153870575521793   \n",
      "\n",
      "                                           full_text in_reply_to_screen_name  \\\n",
      "0  KitchenAid Mixer Sale on @SamsClub | $90 Off P...                    None   \n",
      "1           @KellieShai_ All we need is some milk. üç™             KellieShai_   \n",
      "2  Happy National Chocolate Chip Day! No denying ...                    None   \n",
      "3  This is heartbreaking that less than a year im...                Roja1670   \n",
      "4  @VIZIOsupport I bought a vizio tv from @SamsCl...            VIZIOsupport   \n",
      "\n",
      "  metadata.iso_language_code metadata.result_type              user.id  \\\n",
      "0                         en               recent             20445389   \n",
      "1                         en               recent             86089860   \n",
      "2                         en               recent  1629261957860556800   \n",
      "3                         en               recent  1620973692812496896   \n",
      "4                         en               recent  1620973692812496896   \n",
      "\n",
      "           user.id_str                          user.name user.screen_name  \\\n",
      "0             20445389                           Hip2Save         Hip2Save   \n",
      "1             86089860                         Sam‚Äôs Club         SamsClub   \n",
      "2  1629261957860556800  Celebrate EveryDay by Kellie ShƒÅi      KellieShai_   \n",
      "3  1620973692812496896                    La Sombra Negra         Roja1670   \n",
      "4  1620973692812496896                    La Sombra Negra         Roja1670   \n",
      "\n",
      "   ... user.has_extended_profile user.default_profile  \\\n",
      "0  ...                      True                False   \n",
      "1  ...                     False                False   \n",
      "2  ...                      True                 True   \n",
      "3  ...                      True                 True   \n",
      "4  ...                      True                 True   \n",
      "\n",
      "  user.default_profile_image user.following user.follow_request_sent  \\\n",
      "0                      False          False                    False   \n",
      "1                      False          False                    False   \n",
      "2                      False          False                    False   \n",
      "3                      False          False                    False   \n",
      "4                      False          False                    False   \n",
      "\n",
      "   user.notifications  user.translator_type  sentiment  emotion  \\\n",
      "0               False                  none          1      0.8   \n",
      "1               False                  none          1      0.6   \n",
      "2               False                  none          1      1.0   \n",
      "3               False                  none         -1      0.4   \n",
      "4               False                  none         -1      0.4   \n",
      "\n",
      "                         topic  \n",
      "0               shopping deals  \n",
      "1                    groceries  \n",
      "2  National Chocolate Chip Day  \n",
      "3             customer service  \n",
      "4             customer support  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# Analyze sentiment and emotion\n",
    "df = sentiment_emotion_analysis(df)\n",
    "\n",
    "# Determine topic for each row in 'full_text'\n",
    "df['topic'] = df['full_text'].apply(get_topic)\n",
    "\n",
    "# Save to CSV without index\n",
    "df.to_csv('sentiment_emotion_topic.csv', index=False)\n",
    "\n",
    "# Display first 5 rows\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorization\n",
    "\n",
    "Next we will categorize each post based on it's content into one of the following categories: \n",
    "Content Quality, Customer Support, Spam, Membership issues, Marketing and Other. \n",
    "\n",
    "For each post, we will calculate the category and a score to show the relevancy of the post to the category using the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def categorize_post(text):\n",
    "    \"\"\"\n",
    "    Categorizes a post into predefined categories using an AI model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The post text to categorize.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the category (str) and score (float).\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Given the following post, please categorize it into one of the following categories with a score from 0 (not relevant) to 1 (highly relevant) and all values in between based on how relevant the post is in relation to the category. \n",
    "\n",
    "    Examples:\n",
    "    \n",
    "    Tweet: Finna go to sams club and get a box of nature valley bars and open em in this bed\n",
    "    Answer: Category: Other, Score: 0.5\n",
    "\n",
    "    Tweet: üö® BRAND NEW JUNE @SamsClub 2023 VIDEO üëâüèº\n",
    "    Answer: Category: Marketing, Score: 1\n",
    "\n",
    "    Please provide the category and score in the following JSON format: {{\"category\": <category>, \"score\": <score>}}\n",
    "    \n",
    "    The categories are: \n",
    "\n",
    "    - Content Quality\n",
    "    - Customer Support\n",
    "    - Spam\n",
    "    - Membership Issues\n",
    "    - Marketing\n",
    "    - Other\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4-turbo-preview\",  \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Post:{text}\"}\n",
    "            ],\n",
    "            response_format={ \"type\": \"json_object\" },\n",
    "            temperature=0.3, \n",
    "            max_tokens=60,  \n",
    "            top_p=1.0,  \n",
    "            frequency_penalty=0.0, \n",
    "            presence_penalty=0.0  \n",
    "        )\n",
    "    \n",
    "        result_dict = json.loads(response.choices[0].message.content.strip())\n",
    "        category = result_dict[\"category\"]\n",
    "        score = float(result_dict[\"score\"])\n",
    "        return category, score\n",
    "\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Failed to decode the response into JSON format: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the categorize_post function to each item in the 'full_text' column.\n",
    "# Save the results to new columns 'category' and 'score'.\n",
    "categories_and_scores = df['full_text'].map(categorize_post)\n",
    "df['category'], df['score'] = zip(*categories_and_scores)\n",
    "\n",
    "# Attempt to save the processed data to a CSV file and handle potential errors.\n",
    "try:\n",
    "    df.to_csv('category.csv', index=False)\n",
    "except IOError as e:\n",
    "    print(f\"Error saving to CSV: {e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Cleanup\n",
    "Build the final data that will be used to analyze and create visualizations from the Social Media interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['created_at', 'id', 'full_text', 'in_reply_to_screen_name',\n",
      "       'metadata.iso_language_code', 'metadata.result_type', 'user.id',\n",
      "       'user.id_str', 'user.name', 'user.screen_name', 'user.location',\n",
      "       'user.description', 'user.url', 'user.entities.url.urls',\n",
      "       'user.entities.description.urls', 'user.protected',\n",
      "       'user.followers_count', 'user.friends_count', 'user.listed_count',\n",
      "       'user.created_at', 'user.favourites_count', 'user.geo_enabled',\n",
      "       'user.verified', 'user.statuses_count', 'user.contributors_enabled',\n",
      "       'user.is_translator', 'user.is_translation_enabled',\n",
      "       'user.profile_background_color', 'user.profile_background_image_url',\n",
      "       'user.profile_background_image_url_https',\n",
      "       'user.profile_background_tile', 'user.profile_image_url',\n",
      "       'user.profile_image_url_https', 'user.profile_banner_url',\n",
      "       'user.profile_link_color', 'user.profile_sidebar_border_color',\n",
      "       'user.profile_sidebar_fill_color', 'user.profile_text_color',\n",
      "       'user.profile_use_background_image', 'user.has_extended_profile',\n",
      "       'user.default_profile', 'user.default_profile_image', 'user.following',\n",
      "       'user.follow_request_sent', 'user.notifications',\n",
      "       'user.translator_type', 'sentiment', 'emotion', 'topic', 'category',\n",
      "       'score'],\n",
      "      dtype='object')\n",
      "Index(['created_at', 'post_id', 'full_text', 'in_reply_to_screen_name',\n",
      "       'metadata_iso_language_code', 'metadata_result_type', 'user_id',\n",
      "       'user_id_str', 'user_name', 'user_screen_name', 'user_location',\n",
      "       'user_description', 'user_url', 'user_entities_url_urls',\n",
      "       'user_entities_description_urls', 'user_protected',\n",
      "       'user_followers_count', 'user_friends_count', 'user_listed_count',\n",
      "       'user_created_at', 'user_favourites_count', 'user_geo_enabled',\n",
      "       'user_verified', 'user_statuses_count', 'user_contributors_enabled',\n",
      "       'user_is_translator', 'user_is_translation_enabled',\n",
      "       'user_profile_background_color', 'user_profile_background_image_url',\n",
      "       'user_profile_background_image_url_https',\n",
      "       'user_profile_background_tile', 'user_profile_image_url',\n",
      "       'user_profile_image_url_https', 'user_profile_banner_url',\n",
      "       'user_profile_link_color', 'user_profile_sidebar_border_color',\n",
      "       'user_profile_sidebar_fill_color', 'user_profile_text_color',\n",
      "       'user_profile_use_background_image', 'user_has_extended_profile',\n",
      "       'user_default_profile', 'user_default_profile_image', 'user_following',\n",
      "       'user_follow_request_sent', 'user_notifications',\n",
      "       'user_translator_type', 'sentiment', 'emotion', 'topic', 'category',\n",
      "       'score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Show the current column list\n",
    "print(df.columns)\n",
    "\n",
    "# Refactor column name transformations\n",
    "df.columns = df.columns.str.replace('.', '_', regex=False).str.lower()\n",
    "df = df.rename(columns={'id': 'post_id'})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('finaloutput.csv', index=False)\n",
    "\n",
    "# Print the updated columns to verify changes\n",
    "print(df.columns)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Design / Engineering\n",
    "\n",
    "### Story Generation\n",
    "\n",
    "Our first task is to write a prompt to ask the LLM to create a kids short story. We will have the AI output an HTML table with the names of the characters from the story and their role in the story as well. \n",
    "\n",
    "First, we create a function to run our prompt and get our story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(prompt):\n",
    "    \"\"\"\n",
    "    Generates a story based on the given prompt using an AI model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to generate the story from.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated story content.\n",
    "    \"\"\"\n",
    "    return openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=1,\n",
    "        max_tokens=1000,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    ).choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's just a simple matter of calling the function with our prompt to get our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story:\n",
      "\n",
      "Once upon a time, in a land where the sun dipped low, painting the sky in shades of orange and pink, there stood a little village surrounded by vast, whispering forests. The time was twilight; that magical hour when everything seems possible and fairy tales come to life. In this village, nestled at the foot of a slumbering mountain, lived a boy named Wilhelm.\n",
      "\n",
      "Wilhelm was no ordinary boy; his eyes sparkled with a curiosity that matched the stars, and his laughter was as infectious as the melody of spring. His hair was a mess of tangles, resembling the wild brambles of the woods, and his heart, pure and kind, yearned for adventure beyond the mountains that cradled his home.\n",
      "\n",
      "Among the villagers, two individuals stood out for their wisdom and kindness: Old Martha, a baker whose hands crafted breads that could soothe even the most troubled soul, and Master Henrik, a clockmaker whose timepieces were said to tick in harmony with the heartbeat of the earth. They adored Wilhelm and often indulged his limitless imagination with tales of ancient magic and hidden treasures.\n",
      "\n",
      "One crisp autumn evening, driven by the thirst for adventure and the tales seeded in his heart, Wilhelm embarked on a journey into the forest. His objective was clear; to find the legendary Glowing Mushroom, said to illuminate the darkest night, a treasure that had eluded even the bravest of adventurers.\n",
      "\n",
      "The forest welcomed him with open arms, the trees whispering secrets as he passed. Not long after, Wilhelm encountered a fox, its coat a fiery red against the encroaching night. \"Why do you venture so deep into the night, young one?\" the fox asked, its eyes gleaming with a curious light.\n",
      "\n",
      "Wilhelm shared his quest, and the fox, moved by the boy's courage and simplicity, decided to aid him. Through bramble and creek, the fox guided Wilhelm until, at the heart of the forest, they found it - the Glowing Mushroom, bathing a small clearing in a gentle, ethereal light.\n",
      "\n",
      "Overjoyed, Wilhelm reached out to pluck the mushroom but was stopped by the fox. \"The mushroom must remain here, for it is not just a treasure, but a beacon of hope for those who are lost in the darkness,\" the fox explained.\n",
      "\n",
      "Understanding dawned upon Wilhelm; the true treasure was not the mushroom, but the journey and the friendships formed along the way. With a heart full of gratitude, Wilhelm returned home, the forest whispering blessings upon him.\n",
      "\n",
      "Back in the village, amidst the warm embrace of the villagers, Wilhelm recounted his adventure, his eyes alight with the magic of the journey. And so, the tale of Wilhelm and the Glowing Mushroom became a legend in the village, a testament to the courage found in the heart of a boy and the magic that dwells in the pursuit of dreams.\n",
      "\n",
      "Characters and Roles:\n",
      "\n",
      "```html\n",
      "<table>\n",
      "  <tr>\n",
      "    <th>Character</th>\n",
      "    <th>Role</th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Wilhelm</td>\n",
      "    <td>The main character, a young boy filled with curiosity and courage.</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Old Martha</td>\n",
      "    <td>A baker known for her wisdom and kind-hearted nature.</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Master Henrik</td>\n",
      "    <td>A skilled clockmaker and storyteller beloved by the villagers.</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>The Fox</td>\n",
      "    <td>A mystical creature that guides Wilhelm through the forest.</td>\n",
      "  </tr>\n",
      "</table>\n",
      "```\n",
      "\n",
      "This enchanting tale weaves a tapestry of adventure, magic, and the illuminating power of hope and friendship, capturing the hearts of those who believe in the wonder of fairy tales.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"\"\"\n",
    "# CONTEXT #\n",
    "Craft a children's story in the style of Hans Christian Andersen. \n",
    "\n",
    "# OBJECTIVE #\n",
    "1. Word Count: Ensure the story is no more than 500 words.\n",
    "2. Opening: Start with an imaginative scene to captivate the reader.\n",
    "3. Setting: Include time of day, weather, and immersive details.\n",
    "4. Minor Characters: Introduce them with memorable details.\n",
    "5. Main Character: Describe their appearance, personality, and motivations.\n",
    "6. Plot and Resolution: Create a clear, satisfying story with child-appropriate themes.\n",
    "7. Language: Use vivid imagery and language to engage the reader.\n",
    "\n",
    "# STYLE #\n",
    "Hans Christian Andersen's storytelling style.\n",
    "\n",
    "# TONE #\n",
    "Enchanting and appropriate for young readers.\n",
    "\n",
    "# AUDIENCE #\n",
    "Children and those who enjoy fairy tales.\n",
    "\n",
    "# RESPONSE: Story and HTML Table  #\n",
    "Story: \n",
    "<Insert crafted story here>\n",
    "\n",
    "Characters and Roles: \n",
    "<Insert HTML table here listing characters and their roles in the story>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Call our function to generate the story\n",
    "response_text = generate_story(prompt)\n",
    "print(response_text)\n",
    "\n",
    "# Writing to a file\n",
    "with open(\"StoryGeneration.txt\", \"w\") as file:\n",
    "    file.write(response_text)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story Summarization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the story created by the LLM in the previous task, we will make a summaries. This will consist of two versions: formal and an informal. We will make sure to return and store both versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal Summary: In a magical twilight village, young Wilhelm, known for his curiosity and kind heart, embarks on a quest to find the legendary Glowing Mushroom in the surrounding forest, inspired by tales from beloved villagers Old Martha and Master Henrik. Guided by a wise fox, Wilhelm discovers the mushroom, only to learn that its true value lies not in possession but in the journey and connections made. Returning home enlightened, Wilhelm's adventure becomes a village legend, celebrating the courage and magic inherent in the pursuit of dreams.\n",
      "\n",
      "\n",
      "Informal Summary: So, this kid Wilhelm from a postcard-perfect village decides to go full-on adventurer mode to find this mythical Glowing Mushroom, right? Think of him as your classic, wide-eyed protagonist with a dash of Indiana Jones. He's got this squad of village VIPs, like a magical baker and a clockmaker, hyping him up with old tales. Into the spooky woods he goes, teams up with a sassy red fox, and bam! Finds the mushroom. Plot twist: The fox goes all wise on him, saying the shroom's not for taking; it's a hope beacon. Wilhelm gets it, the treasure was the ride and the buds made along the way. He heads home, becomes a legend, and pretty much lives the \"it's about the journey\" clich√©. Classic Wilhelm, am I right?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the story text to extract the relevant part\n",
    "story = response_text.split('Characters and Roles:')[0].strip()\n",
    "\n",
    "# Create formal summary\n",
    "prompt_formal = f\"\"\"\n",
    "# CONTEXT #\n",
    "You are an expert in story summary writing. Your task is to provide a formal summary of a given story.\n",
    "\n",
    "# OBJECTIVE #\n",
    "Produce a concise, professional summary suitable for publication. Focus on summarizing the story's content and extracting key information and arguments. The summary should be comprehensive, detailed, yet concise, limited to no more than 100 words.\n",
    "\n",
    "# STYLE #\n",
    "Professional, formal\n",
    "\n",
    "# TONE #\n",
    "Objective, Clear\n",
    "\n",
    "# AUDIENCE #\n",
    "Readers seeking a succinct overview of the story for publication purposes.\n",
    "\n",
    "# RESPONSE FORMAT #\n",
    "Provide the summary in the following structure:\n",
    "\n",
    "Formal Summary: [Insert summary here]\n",
    "\n",
    "# STORY TEXT #\n",
    "{story}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_formal = openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_formal}],\n",
    "        temperature=0.10,\n",
    "        max_tokens=200,\n",
    "        top_p=0.50,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "formal_summary = response_formal.choices[0].message.content\n",
    "\n",
    "print(formal_summary + \"\\n\\n\")\n",
    "\n",
    "\n",
    "# Create informal summary\n",
    "prompt_informal = f\"\"\"\n",
    "# CONTEXT #\n",
    "You're taking on the role of a casual, yet expert, story summarizer.\n",
    "\n",
    "# OBJECTIVE #\n",
    "Craft a fun, informal summary of the provided story, as if you're chatting with a good friend. Your goal is to cover the story's main points and key details in an engaging way. Keep it light, lively, and no more than 100 words.\n",
    "\n",
    "# STYLE #\n",
    "Conversational, like you're explaining to a friend\n",
    "\n",
    "# TONE #\n",
    "Lighthearted, Engaging\n",
    "\n",
    "# AUDIENCE #\n",
    "A good friend interested in a quick, entertaining rundown of the story.\n",
    "\n",
    "# RESPONSE FORMAT #\n",
    "Deliver the summary as follows:\n",
    "\n",
    "Informal Summary: [Insert summary here]\n",
    "\n",
    "# STORY TEXT #\n",
    "{story}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response_informal = openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_informal}],\n",
    "        temperature=0.80,\n",
    "        max_tokens=200,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "\n",
    "informal_summary = response_informal.choices[0].message.content\n",
    "\n",
    "print(informal_summary +\"\\n\")\n",
    "\n",
    "# Save the responses to a text file\n",
    "with open(\"Summarization.txt\", \"w\") as file:\n",
    "    file.write(\"Formal Summary:\\n\" + formal_summary + \"\\n\\nInformal Summary:\\n\" + informal_summary)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation\n",
    "\n",
    "Now we will translate the summary into three languages of your preference. The result will be stored in JSON format where keys are the languages for consumption later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['Spanish', 'French', 'German']\n",
    "formal_translations = {}\n",
    "informal_translations = {}\n",
    "\n",
    "for language in languages:\n",
    "    # Translate formal summary\n",
    "    prompt_formal = (\n",
    "        f\"Translate the following English text to {language}:\\n\\n\"\n",
    "        f\"{formal_summary}\"\n",
    "    )\n",
    "    \n",
    "    response_formal = openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_formal}],\n",
    "        temperature=0,\n",
    "        max_tokens=200,\n",
    "        top_p=0.30,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "\n",
    "    formal_translations[language] = response_formal.choices[0].message.content\n",
    "\n",
    "    # Translate informal summary\n",
    "    prompt_informal = (\n",
    "        f\"Translate the following English text to {language}:\\n\\n\"\n",
    "        f\"{informal_summary}\"\n",
    "    )\n",
    "\n",
    "    response_informal = openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_informal}],\n",
    "        temperature=0,\n",
    "        max_tokens=200,\n",
    "        top_p=0.30,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    \n",
    "    informal_translations[language] = response_informal.choices[0].message.content\n",
    "\n",
    "# Store results in JSON format\n",
    "translations_json = json.dumps({\n",
    "    \"formal_translations\": formal_translations,\n",
    "    \"informal_translations\": informal_translations\n",
    "}, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Write JSON string to a file\n",
    "with open('translations.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(translations_json)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Service Automation\n",
    "\n",
    "For our last example, we will examine customer service response automation. Based on a product review, we will ask the LLM to write a customer service email addressing the client's review. We should be careful to take into account the clients sentiment when writing a response. Additionally, we will also create action items as suggestions for the company to take based on the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      " Customer \n",
      "Dear [Customer's Name],\n",
      "\n",
      "Thank you very much for taking the time to share your detailed review of the Z-Blend Master Blender System. We truly value your feedback and are committed to ensuring our customers have a positive experience with our products. We understand your concerns regarding the price fluctuation and the issues you encountered with the build quality and durability of the blender. It's disappointing to hear that your excitement was dampened by these experiences, and we sincerely apologize for any inconvenience this may have caused.\n",
      "\n",
      "We appreciate your tips for making smoothies and your overall positive comments about the design and delivery service. It‚Äôs insights like yours that help us improve and strive to deliver the best possible products and services. Regarding the motor noise issue you faced, we regret to hear that it occurred just after the warranty period. We would like to learn more about this and see how we can assist you further. Please contact our customer service team at your earliest convenience, and we will work with you to find a satisfactory resolution.\n",
      "\n",
      "Our aim is to ensure that every customer feels valued and heard. We're taking your feedback seriously and are already looking into ways to address the concerns you've raised. Thank you again for your honest review, and we hope to have the opportunity to restore your confidence in our brand.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "[Your Name]\n",
      "Customer Service Team, Z-Blend \n",
      "\n",
      "Action Items:\n",
      " - **Review Pricing Strategy**: Examine our pricing model, especially during sales periods, to ensure transparency and fairness. Consider implementing a price guarantee for recent purchases before a sale.\n",
      "- **Quality Control Measures**: Reinforce quality checks on the blender system, particularly focusing on the durability of parts such as the blade locking mechanism.\n",
      "- **Warranty and Customer Support Enhancement**: Evaluate our warranty period and customer service policies to see if improvements can be made, particularly in assisting customers who experience issues shortly after the warranty expires.\n",
      "- **Product Development**: Incorporate feedback regarding the build quality and durability into future product development. Consider re-engineering parts that have shown to be less durable over time.\n",
      "- **Customer Education**: Develop more comprehensive guides and tips for product care and usage, potentially extending the life of the product and enhancing customer satisfaction. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Product review from the customer\n",
    "review = \"\"\"\n",
    "Product Review: Z-Blend Master Blender System\n",
    "\n",
    "I recently had the opportunity to try out the Z-Blend Master Blender System and I'd like to share my detailed review of this product. During the month of November, I was thrilled to discover that the 17-piece system was on a seasonal sale, priced at a mere $49, which was nearly half off the original price. However, my excitement was short-lived when, around the second week of December, the prices skyrocketed to around $70-$89 for the same system, leaving me a bit puzzled and skeptical about the sudden price increase.\n",
    "\n",
    "In terms of design and build quality, the Z-Blend Master Blender System has an overall appealing look. However, upon closer examination, I noticed that the part where the blade locks into place doesn't appear as robust as in previous editions released a few years ago. Despite this observation, I intend to handle the blender with utmost care, especially since I use it to crush hard items like beans, ice, and rice. My blending technique involves initially pulverizing these items in the blender before switching to the whipping blade to achieve a finer flour consistency. Similarly, when preparing smoothies, I utilize the cross-cutting blade initially and then switch to the flat blade if I prefer a smoother and less pulpy texture.\n",
    "\n",
    "For those who enjoy making smoothies, I have a helpful tip to share. It's best to finely cut and freeze the fruits and vegetables before blending them. This way, you can reduce the amount of ice needed while still achieving a delicious and refreshing smoothie. In the case of making sorbet, I've found that using a small to medium-sized food processor yields excellent results.\n",
    "\n",
    "After approximately a year of regular use, I did encounter a minor issue with the Z-Blend Master Blender System. The motor started making an unusual noise, prompting me to reach out to customer service. Unfortunately, I discovered that the warranty had already expired, requiring me to purchase a new blender. It's worth noting that the overall quality of similar products in the market seems to have declined over time. Manufacturers seem to rely on brand recognition and consumer loyalty to maintain sales, rather than consistently improving the product's durability.\n",
    "\n",
    "On a positive note, the delivery service for the Z-Blend Master Blender System was commendable. I received the product within just two days of placing my order, which exceeded my expectations and demonstrated excellent customer service.\n",
    "\n",
    "In conclusion, the Z-Blend Master Blender System offers satisfactory performance and functionality, despite some concerns about the build quality. The fluctuating prices during the sales period are a noteworthy aspect to consider, as it raises questions about fair pricing practices. Given my experience with the motor issue and the general decline in product quality, I recommend potential buyers thoroughly evaluate their options before making a purchase decision.\n",
    "\"\"\"\n",
    "\n",
    "# Main prompt to get our response\n",
    "prompt = f\"\"\"\n",
    "# CONTEXT #\n",
    "Act as a customer service agent responding to a product review given by a customer.\n",
    "\n",
    "# OBJECTIVE #\n",
    "1. Craft a response to the customer's review.\n",
    "2. Generate a bulleted list of actionable steps for the company based on the review's content.\n",
    "\n",
    "# STYLE #\n",
    "Professional and friendly with an empathetic tone.\n",
    "\n",
    "# TONE #\n",
    "Understanding and reassuring, aiming to placate the customer.\n",
    "\n",
    "# AUDIENCE #\n",
    "The primary audience is the customer who wrote the review. The secondary audience is the company's internal team.\n",
    "\n",
    "# RESPONSE FORMAT #\n",
    "1. Customer Response: A composed response in 2-3 paragraphs addressing the customer's concerns expressed in the review.\n",
    "2. Action Items: A list of 2-5 bullet points outlining steps for internal company action.\n",
    "\n",
    "Response:\n",
    "<Compose the response to the customer here, adhering to the specified style and tone>\n",
    "\n",
    "Action Items:\n",
    "<Bullet list of 2-5 action items for internal company use based on the review's issues>\n",
    "\n",
    "# INSTRUCTIONS #\n",
    "- Analyze the customer's review.\n",
    "- Draft a response that acknowledges the customer's experience, offers empathy, and suggests a resolution or next step.\n",
    "- Identify key issues in the review and create actionable steps for the company to address these issues.\n",
    "\n",
    "{review}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Obtain completion from the model\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.6,\n",
    "    max_tokens=2000,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0\n",
    ")\n",
    "\n",
    "# Extract the response text\n",
    "response_text = response.choices[0].message.content\n",
    "\n",
    "# Find the start index of the Action Items section\n",
    "action_items_start = response_text.find(\"Action Items:\")\n",
    "\n",
    "# Extract the response to the customer\n",
    "response_to_customer = response_text[:action_items_start].strip().replace(\"Response:\", \"\").strip()\n",
    "\n",
    "# Extract the action items\n",
    "action_items = response_text[action_items_start:].replace(\"Action Items:\", \"\").strip()\n",
    "\n",
    "# Print the extracted sections\n",
    "print(\"Response:\\n\", response_to_customer, \"\\n\")\n",
    "print(\"Action Items:\\n\", action_items, \"\\n\")\n",
    "\n",
    "# Write the response and action items to a text file\n",
    "with open(\"TextAutomation.txt\", \"w\") as file:\n",
    "    file.write(f\"Response:\\n{response_to_customer}\\n\\nAction Items:\\n{action_items}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7051bc8ea4b6bb7eaa9a718c339c0914aee7e1d37a991e7052badef2075df338"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
